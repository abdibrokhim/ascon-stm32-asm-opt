# Code Optimization for STM32F103/STM32F407 Discovery Boards – Time and Memory Analysis

# Discussion

## Summary of Key Findings

The experimental results demonstrate clear benefits from low-level code optimization on STM32F103 and STM32F407 microcontrollers. In the case of the bubble sort algorithm, the hand-optimized Assembly implementation achieved a substantially faster execution time compared to the straightforward C version. This confirms that even a simple algorithm can be sped up by eliminating high-level overhead through manual tuning. Similarly, for the cryptographic algorithms, notable performance improvements were observed when moving from unoptimized C to optimized implementations. The Assembly-tuned version of the ASCON AEAD128 cipher ran **\~11.11% faster** than its original C implementation, reflecting a modest but significant speedup. The GOST 28147-89 block cipher saw an even more dramatic enhancement: the optimized code executed in roughly half the time of the baseline, corresponding to a **49.13% reduction in execution time**. These timing gains were often accompanied by reductions in memory footprint. Across all three case studies, the optimized code tended to use fewer instructions and less program memory than the compiler-generated code, an important benefit on devices with limited Flash and RAM. Taken together, these findings confirm that targeted optimizations at the assembly level can yield faster and leaner code on Cortex-M3/M4 based boards, with measured improvements ranging from incremental (on the order of 10%) to very substantial (nearly 50% or more), depending on the algorithm.

## Interpretation and Comparison with Existing Literature

Interpreting these results reveals how algorithm characteristics and compiler behavior influence the gains from manual optimization. The relatively modest 11.11% speed boost for ASCON suggests that this lightweight cipher’s C implementation was already efficient – likely a result of ASCON’s design being tailored for simplicity and speed on constrained hardware. In contrast, the much larger 49.13% speedup for GOST indicates that the original C code left significant room for improvement. GOST 28147-89 is an older cipher not originally developed with microcontroller efficiency in mind; our findings align with reports that GOST suffered from performance limitations on modern processors. By carefully optimizing GOST’s inner loops and cryptographic operations in assembly (for example, streamlining its S-box substitutions and bit rotations), we exploited opportunities the compiler did not fully capitalize on. This led to nearly halving the execution time – a gain consistent with the notion that manual low-level optimizations can substantially outperform compiler output when the algorithm involves patterns that are challenging for automated optimizers.

Comparing our work to the broader literature, we see both confirmation and context for these improvements. Prior studies and practitioner reports have noted that modern optimizing compilers generate highly efficient code for many tasks, often narrowing the gap between C and assembly performance. Our ASCON result supports this: a roughly 10% gain implies that the ARM C compiler was already handling most optimizations well. However, our GOST result underscores that exceptions remain where hand tuning shines. This phenomenon is well-known in high-performance computing and cryptography – for instance, in a recent multimedia library update, hand-written assembly using specialized instructions achieved **up to 94× faster** execution than a baseline C implementation. While that extreme case leveraged AVX-512 vector instructions on a PC processor, the underlying principle is analogous: by leveraging hardware capabilities and fine-tuning instruction-level parallelism beyond what the compiler attempts, one can realize outsized performance gains. Our work applies this principle in the microcontroller realm, showing that even on a relatively simple Cortex-M core, there are performance reserves that a human optimizer can tap into. Notably, cryptographic algorithms are often hand-optimized in industry (e.g. in OpenSSL or ARM CryptoCell libraries) to meet throughput and memory goals on embedded devices. Our results are in line with those practices, quantitatively illustrating the benefits. It is also instructive that the bubble sort – a conceptually simple but O(n²) algorithm – saw improvement but remains far slower than more efficient sorting algorithms would be. This highlights a key point often echoed in literature: micro-optimizations (like hand coding in assembly) can boost performance by constant factors, but they do not overcome fundamental algorithmic complexity limits. In our context, the bubble sort experiment serves as a didactic example of optimization rather than a recommendation to use bubble sort; it reinforces that for non-cryptographic tasks, choosing better algorithms (e.g. quicksort) is usually the preferred route to improve performance, whereas for cryptographic routines the algorithm is fixed and low-level optimization becomes crucial.

## Practical and Theoretical Implications

These findings carry several practical and theoretical implications for embedded computing and IoT. Practically, the improvements in execution speed translate directly into more efficient use of processor time on resource-constrained systems. On microcontrollers like the STM32F103/F407, a faster execution means the CPU can return to sleep mode sooner or handle other tasks, which is especially valuable in battery-powered **IoT (Internet of Things)** nodes. An 11% reduction in cryptographic processing time for ASCON, and a nearly 50% reduction for GOST, can significantly decrease the active CPU time needed for secure communications. This, in turn, implies lower energy consumption and extended battery life for devices performing these operations, since energy use is roughly proportional to active execution time for a fixed clock speed. The memory savings from our optimizations (smaller code size and possibly lower RAM usage) similarly mean that more functionality can be packed into a microcontroller’s limited memory, or cheaper/simpler microcontrollers might be used for the same task. This is highly relevant as IoT devices often have severe memory and storage constraints. From a theoretical perspective, our work underscores that **software efficiency** remains a critical concern in an era increasingly characterized by high-level abstractions. It demonstrates that understanding the underlying hardware architecture (in this case, the 32-bit ARM Cortex-M core) and tailoring code to it can yield measurable performance gains. This insight supports the continued relevance of low-level computer architecture knowledge in the domain of embedded systems. It also speaks to the design of cryptographic algorithms: ASCON’s relatively small improvement suggests that algorithms explicitly designed for efficiency can get quite close to optimal performance even in high-level implementations. Meanwhile, GOST’s case shows that algorithms not originally intended for lightweight environments can benefit hugely from optimization – implying that when updating or standardizing ciphers for modern use, performance on constrained hardware should be a key consideration (as was indeed the case when GOST was succeeded by more efficient designs).

In a broader sense, our results highlight a trade-off between development convenience and runtime efficiency. High-level C code allows quicker development and portability, but our experiments demonstrate that there are scenarios where investing effort into manual optimization is warranted. This has implications for the development process in embedded projects: critical code sections (such as encryption, signal processing, or time-sensitive loops) might justify the extra time of hand optimization to meet strict performance or energy targets. The fact that we achieved significant gains without altering the algorithms themselves also reinforces theoretical principles of performance engineering – namely, that beyond algorithmic complexity, constant factors matter in practice. For IoT devices performing encryption or sorting, those constant-factor improvements can be the difference between meeting real-time requirements or not. Hence, both practitioners and researchers should note that there is still “low-hanging fruit” in performance tuning at the instruction level, even as compilers improve, especially for specialized workloads like cryptography.

## Limitations

It is important to acknowledge the limitations of this work. First, the scope of our study is limited to two specific microcontroller platforms: the STM32F103 (Cortex-M3) and STM32F407 (Cortex-M4) Discovery boards. While these are popular representatives of 32-bit ARM microcontrollers, the results may not directly generalize to other architectures (such as 8-bit AVR microcontrollers or 32-bit RISC-V cores) or even to newer ARM Cortex-M models with different features. The optimizations we performed were manual and tailored to the STM32F1/F4 hardware. This means the assembly code is architecture-specific – a necessity for maximizing performance, but a limitation for portability. Another limitation is that we focused purely on software execution on the CPU core and did not compare our software implementations against any hardware acceleration. Some microcontrollers include dedicated cryptographic accelerators or DSP instructions that could perform sorting or encryption faster than software; we did not evaluate such features, since our goal was to compare C and assembly on the same general-purpose CPU. As a result, the improvements we report are specific to software-based execution. Furthermore, our optimizations were done by hand, which introduces a human factor: the quality of assembly output depends on the programmer’s expertise. It is possible that an even more skilled assembly programmer or an alternate optimization strategy could achieve further improvements, or conversely that our assembly code could be suboptimal in ways we did not realize. We also did not formally verify properties like constant-time execution for cryptographic code – our focus was performance, so side-channel resistance (e.g., consistent timing to thwart timing attacks) was not explicitly analyzed and could be a concern in a real security context.

Maintainability and development effort are additional implicit limitations of manual optimization. Writing assembly is time-intensive and error-prone, and the resulting code can be harder to debug and maintain compared to C. In a production environment, this means that our optimized routines might incur higher long-term costs if the underlying algorithms need to change or if the code is reused on a different platform. This is a known drawback of hand-optimized code: such **low-level optimizations are typically reserved for performance-critical components and require specialized expertise in low-level programming**. Finally, our evaluation of “memory analysis” was constrained to basic metrics (such as code size and perhaps stack or heap usage) and we did not measure dynamic memory behavior in depth. We note that memory on microcontrollers includes not just Flash for code but also SRAM for runtime data; our study did not uncover significant issues with RAM usage in any implementation, but we did not stress-test memory beyond the needs of the algorithms. In summary, the findings, while encouraging, come with the caveat that they are demonstrated in a controlled setting on specific hardware and with specific algorithms, using manual methods that might not scale to large applications.

## Suggestions for Practical Applications

Despite the above limitations, our optimized code has clear potential for practical applications in the embedded and IoT domain. One immediate application is in **battery-sensitive IoT nodes** that perform secure data transmission. For example, a remote sensor node that encrypts its readings (to send over a wireless network) could integrate the assembly-optimized ASCON implementation to reduce encryption latency and energy consumption. The 11% speedup in encryption might directly translate into roughly that percentage of energy saved during each encryption operation – a meaningful gain for devices expected to run on small batteries for months or years. In scenarios where the energy budget is extremely tight, even single-digit percentage improvements are valuable. The GOST algorithm, while perhaps less commonly used internationally than AES or ASCON, is still relevant in certain regions; an IoT gateway or controller that must support GOST for legacy reasons could use our optimized code to handle cryptographic tasks much more efficiently, possibly enabling the use of a lower-clocked (and thus lower-power) microcontroller than would otherwise be needed. More broadly, any embedded system that must perform sorting or cryptographic transformations under real-time constraints could benefit from our findings. For instance, a small-scale data logger that needs to sort incoming data or a wearable device that encrypts stored data might incorporate similar optimization techniques to ensure smooth operation. The reduced code size from our assembly routines also means they can be deployed on devices with very limited Flash memory. This could expand the range of devices capable of running advanced encryption – for example, enabling even a tiny Cortex-M0 based sensor to use ASCON for authentication, whereas the larger C implementation might not have fit on that class of device. In summary, the optimized algorithms from this thesis can be seen as building blocks for **efficient firmware** in any context where performance and memory are at a premium. Developers targeting ultra-low-power or timing-critical applications can adopt these techniques (and code) to get more out of the modest hardware resources typical of IoT endpoints and embedded controllers.

## Recommendations for Further Research

This work opens several avenues for further research and development. A logical next step is to evaluate the generality of our optimizations across a broader range of hardware. Future studies could port our optimized code to other microcontrollers – for instance, ARM Cortex-M0+, Cortex-M7, or even non-ARM architectures like RISC-V and PIC32 – to measure whether similar speedups are obtained. Such an investigation would reveal how much of the improvement was due to general algorithmic optimizations versus exploiting very specific features of the Cortex-M3/M4. Another recommendation is to conduct a thorough **power consumption analysis** in tandem with performance. While faster execution usually implies lower energy per operation (since the CPU runs for a shorter duration), the relationship is not always linear due to factors like clock frequency scaling and active vs sleep power modes. Measuring the actual energy saved by our optimizations on battery-powered devices would quantify their practical impact in IoT scenarios. Additionally, examining the **side-channel resilience** of the optimized cryptographic implementations would be valuable. Sometimes, performance optimizations (especially in cryptography) can inadvertently affect the constant-time behavior of code or make power consumption patterns more data-dependent, potentially making the algorithm more susceptible to timing or power analysis attacks. Future work could analyze whether our assembly versions of ASCON and GOST maintain the same level of side-channel security as their high-level counterparts, and if not, explore techniques to balance security and speed (for example, by inserting balancing operations or using hardware features to randomize execution timing).

From a software engineering perspective, further research could look into automating some of the optimization process. Tools like LLVM or GCC with machine-specific optimizations, or the use of intrinsic functions and profile-guided optimizations, might achieve part of the benefits of hand-written assembly with less manual effort. It would be useful to compare our hand-tuned assembly with code generated by an auto-vectorizing compiler or with upcoming technologies like AI-assisted code optimization, to see where humans still have the edge and where toolchains can be improved. Moreover, exploring other algorithms and use cases would broaden the insights: for instance, optimizing a more complex sorting algorithm, or other cryptographic primitives (like AES or hashing functions) on the same hardware, would help determine if the patterns observed (e.g. diminishing returns for already-efficient algorithms vs huge gains for legacy ones) hold generally. Finally, given that our study focused on performance and memory, a potential extension would be to evaluate system-level impact: integrating the optimized routines into a full IoT application and observing metrics like overall throughput, latency, and battery longevity. Such end-to-end experimentation would solidify the case for low-level optimization by demonstrating benefits at the application level, and might uncover interactions (such as I/O or network delays masking CPU gains) that are important when deploying these optimizations in real-world systems. By pursuing these further research directions, one can build on this thesis to develop a more comprehensive understanding of code optimization strategies for embedded systems, guiding both the design of future algorithms and the best practices for implementing them on microcontroller platforms.
